{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb78b6f-753e-4004-bcd8-49efe6cec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a4da04-a613-4664-83d0-ef8781cf853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf7ed2b-c5ee-4422-b1d7-0405cd227e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import utils\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import datasets\n",
    "from keras.layers import InputLayer\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import History\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras import losses\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78899b29-c2cf-4658-8446-567b10572990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/simple-guide-to-hyperparameter-tuning-in-neural-networks-3fe03dad8594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b20e26-bb8d-4238-9fb4-7ca2ce1c943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b0ffa5-4e93-4b24-95fe-24bcbb7d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "#split into training data and testing data (usually 80-20)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4077160-0f15-48d3-9c9e-0b31d52d0d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check the dataset\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea915684-a24b-45ed-aacb-e97fbbd6a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training sets so instead of having colours go from 0-255 they now go \n",
    "#from 0-1 based on the length of the axis\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1838f6-f278-4103-8643-9be4f18bc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the 2D images into 1D vectors\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Check the column length\n",
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244e98f8-acf6-468e-aa59-0aa5e7d97dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9233bb80-3ba4-4324-abce-a8dea30e23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD)\n",
    "epochs=60\n",
    "#Hyperparameters (typical values are learning_rate = 0.1, decay=1e-6, momentum=0.9, and nesterov=True\n",
    "#learning_rate = 0.1\n",
    "#decay_rate = learning_rate / epochs\n",
    "#momentum = 0.8\n",
    "\n",
    "sgd = SGD(learning_rate=0.1, momentum=0.8, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94339e-dca9-4322-8adb-192e960f2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "lr_model = Sequential()\n",
    "lr_model.add(Dense(64, activation=tf.nn.relu, kernel_initializer='uniform', \n",
    "                input_dim = input_dim)) \n",
    "lr_model.add(Dropout(0.1))\n",
    "lr_model.add(Dense(64, kernel_initializer='uniform', activation=tf.nn.relu))\n",
    "lr_model.add(Dense(num_classes, kernel_initializer='uniform', activation=tf.nn.softmax))\n",
    "\n",
    "# compile the model\n",
    "lr_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ecc0e9-15d6-4d53-b2e5-f49852b3cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the model\n",
    "batch_size = int(input_dim/100)\n",
    "\n",
    "lr_model_history = lr_model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c5473-27c8-4257-9930-7235d41c3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(lr_model_history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(lr_model_history.history['acc']), 'r', label='train')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_acc']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5acba0-060e-4ea9-b865-5dfc1539895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent (SGD)\n",
    "epochs=60\n",
    "#Hyperparameters (typical values are learning_rate = 0.1, decay=1e-6, momentum=0.9, and nesterov=True\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "#momentum = 0.8\n",
    "\n",
    "sgd = SGD(learning_rate=0.1, momentum=0.8, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9268b8-9d8e-4c6a-a01d-0fedcead003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_dim = x_train.shape[1]\n",
    "num_classes = 10\n",
    "batch_size = 196\n",
    "\n",
    "exponential_decay_model = Sequential()\n",
    "exponential_decay_model.add(Dense(64, activation=tf.nn.relu, kernel_initializer='uniform', input_dim = input_dim))\n",
    "exponential_decay_model.add(Dropout(0.1))\n",
    "exponential_decay_model.add(Dense(64, kernel_initializer='uniform', activation=tf.nn.relu))\n",
    "exponential_decay_model.add(Dense(num_classes, kernel_initializer='uniform', activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "exponential_decay_model.compile(loss='categorical_crossentropy', \n",
    "                                optimizer=sgd, \n",
    "                                metrics=['acc'])\n",
    "\n",
    "# define the learning rate change \n",
    "def exp_decay(epoch):\n",
    "    lrate = learning_rate * np.exp(-decay_rate*epoch)\n",
    "    return lrate\n",
    "\n",
    "# learning schedule callback\n",
    "loss_history = History()\n",
    "lr_rate = LearningRateScheduler(exp_decay)\n",
    "callbacks_list = [loss_history, lr_rate]\n",
    "\n",
    "# you invoke the LearningRateScheduler during the .fit() phase\n",
    "exponential_decay_model_history = exponential_decay_model.fit(x_train, y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=epochs,\n",
    "                                    callbacks=callbacks_list,\n",
    "                                    verbose=1,\n",
    "                                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fe5ce-5070-4a00-8db6-11ca2d3d92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(exponential_decay_model_history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(exponential_decay_model_history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(exponential_decay_model_history.history['acc']), 'r', label='train')\n",
    "ax.plot(np.sqrt(exponential_decay_model_history.history['val_acc']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59418d2-8b6e-4fca-a5f7-a43bfb6f8de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation=tf.nn.relu, kernel_initializer='uniform', \n",
    "                input_dim = input_dim)) # fully-connected layer with 64 hidden units\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, kernel_initializer='uniform', activation=tf.nn.relu))\n",
    "model.add(Dense(num_classes, kernel_initializer='uniform', activation=tf.nn.softmax))\n",
    "\n",
    "# defining the parameters for RMSprop (I used the keras defaults here)\n",
    "rms = RMSprop(learning_rate=0.001, rho=0.9, decay=0.0)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rms,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae400a-3683-4d56-986a-820852d9f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = input_dim\n",
    "epochs = 60\n",
    "\n",
    "model_history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfaae8-0eb3-4818-9025-f0a67ce49ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['acc']), 'r', label='train_acc')\n",
    "ax.plot(np.sqrt(model_history.history['val_acc']), 'b' ,label='val_acc')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model_history.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model_history.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecb5c8-f2fd-4f7d-8a7a-8b696780e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function that creates the model (required for KerasClassifier) \n",
    "# while accepting the hyperparameters we want to tune \n",
    "# we also pass some default values such as optimizer='rmsprop'\n",
    "def create_model(init_mode='uniform'):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, kernel_initializer=init_mode, activation=tf.nn.relu, input_dim=784)) \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, kernel_initializer=init_mode, activation=tf.nn.relu))\n",
    "    model.add(Dense(10, kernel_initializer=init_mode, activation=tf.nn.softmax))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6ac89-2730-48b0-b5bc-b97282a78013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model_CV = KerasClassifier(model=create_model, epochs=epochs, \n",
    "                           batch_size=batch_size, verbose=1, init_mode='uniform')\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', \n",
    "             'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a07a7e-faa4-4691-91af-d5cac5756928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f' mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cc36a-d15d-4a1b-9f78-7c3ec934dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat some of the initial values here so we make sure they were not changed\n",
    "input_dim = x_train.shape[1]\n",
    "num_classes = 10\n",
    "\n",
    "# let's create a function that creates the model (required for KerasClassifier) \n",
    "# while accepting the hyperparameters we want to tune \n",
    "# we also pass some default values such as optimizer='rmsprop'\n",
    "def create_model_2(activation_function='relu',optimizer='rmsprop', init='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, kernel_initializer=init, activation=activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, kernel_initializer=init, activation=activation_function))\n",
    "    model.add(Dense(num_classes, kernel_initializer=init, activation=tf.nn.softmax))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dbb62-1568-4241-8c3b-d61e624b3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# fix random seed for reproducibility (this might work or might not work \n",
    "# depending on each library's implenentation)\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create the sklearn model for the network\n",
    "model_init_batch_epoch_CV = KerasClassifier(model=create_model_2, batch_size = 40, verbose=1, epochs = 10, init = \"uniform\")\n",
    "model_init_batch_epoch_CV\n",
    "# # we choose the initializers that came at the top in our previous cross-validation!!\n",
    "init_mode = ['uniform', 'glorot_uniform', 'he_uniform'] \n",
    "batches = [128, 512]\n",
    "epochs = [10, 20]\n",
    "activation = ['relu', 'sigmoid']\n",
    "\n",
    "\n",
    "# # grid search for initializer, batch size and number of epochs\n",
    "param_grids = dict(epochs=epochs, batch_size=batches, init=init_mode)\n",
    "grid = GridSearchCV(estimator=model_init_batch_epoch_CV, \n",
    "                    param_grid=param_grids,\n",
    "                    cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d5523-146c-462b-ab7a-bd9dc73e00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init_batch_epoch_CV.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609910e3-21a6-42f2-8db0-b33a90886ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'mean={mean:.4}, std={stdev:.4} using {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c22cc-34bf-4e71-8a92-c001b27d1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One last question before we end: what do we do if the number of parameters and values we have to cycle through in our GridSearchCV is particularly large?\n",
    "\n",
    "#This can be a particularly troublesome problem — imagine a situation where there are five parameters being selected for and 10 potential values that we have selected for each parameter. The number of unique combinations of this is 10⁵, which means we would have to train a ridiculously large number of networks. It would be insanity to do it this way, so it is common to use RandomizedCV as an alternative.\n",
    "\n",
    "#RandomizedCV allows us to specify all of our potential parameters. Then for each fold in the cross-validation, it selects a random subset of parameters to use for the current model. In the end, the user can select the optimal set of parameters and use these as an approximate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39dba0a-d1c8-481e-a46f-122fb6e4c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "\n",
    "#creatae layers and set activation\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#add the first layer which flattens the later from 28x28 to a 784 layer\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "#Add second layer (dense), which is just a basic layer which is connected to all neurons\n",
    "#First mention how many neuros\n",
    "#Secondly mention the activation (relu = rectivy linear unit returns x if x > 0 and 0 if x<= 0) \n",
    "#different activation (relu, sigmoid, tanh, elus, etc.\n",
    "model.add(tf.keras.layers.Dense(128, activation='sigmoid', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(tf.keras.layers.Dense(128, activation='sigmoid', kernel_initializer='he_uniform'))\n",
    "\n",
    "#Output layer, represents individual numbers 0-9\n",
    "#Activation softmax = gives the highest probability of a specific individual number\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', kernel_initializer='he_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10fd82-7ed7-436d-be92-283d97dc42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the parameters for RMSprop (I used the keras defaults here)\n",
    "rms = RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e445e0-2a50-499f-a1a3-d32b061c8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=60,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f45856-896e-46cb-8b62-493f037a4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_neural_network_2_0.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fcb83-0ce0-4c1b-83df-a3f982753ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model if you have it saved to skip training steps\n",
    "model = tf.keras.models.load_model('trained_neural_network_2_0.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20e04d-8a23-4edd-a409-887108774f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize image number\n",
    "image_number = 1\n",
    "\n",
    "#while you have more images\n",
    "while os.path.isfile(f\"Hand written numbers/digit{image_number}.png\"):\n",
    "    try:\n",
    "        #read the image\n",
    "        img = cv2.imread(f\"Hand written numbers/digit{image_number}.png\")[:,:,0]\n",
    "        #invert the colours (black to white and white to black) and make into an array\n",
    "        img = np.invert(np.array([img]))\n",
    "        #now predict the number of the image using the model\n",
    "        prediction = model.predict(img)\n",
    "        #print prediction np.argmax gives the field that has the highest number\n",
    "        print(f\"the number is probably a {np.argmax(prediction)}\")\n",
    "        plt.imshow(img[0], cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Error!\")\n",
    "    finally:\n",
    "        image_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b89fc-f2ba-4665-bba6-8e4bae7ffb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_01.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9cae8-34e4-446e-aac9-d76cf1b1987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model.history['acc']), 'r', label='train_acc')\n",
    "ax.plot(np.sqrt(model.history['val_acc']), 'b' ,label='val_acc')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model.history['loss']), 'r', label='train')\n",
    "ax.plot(np.sqrt(model.history['val_loss']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881b42d-fdc8-4c22-88a0-11fa09bc09fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
